{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import openai api\n",
    "# load api key\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some text data\n",
    "# a list of summer school introductions\n",
    "summer_school_introductions = {\n",
    "    'bse_data_science':{'intro':\n",
    "    \"\"\"This summer school is held at the Barcelona School of Economics. Over the last few years machine learning techniques have become increasingly popular and widely used in both \n",
    "    academia and the industry. The BSE Data Science Summer School provides an overview of the state-of-the-art tools employed in machine \n",
    "    learning. \"Foundations of Data Science\" is an introductory course that provides a broad overview of the main methodologies used to \n",
    "    analyze data in data science. \"Harnessing Language Models: Your Path to NLP Expert\" and \"Statistical Machine Learning for Large and \n",
    "    Unstructured Data\" are advanced courses focusing on more specialized topics. The teaching style of the courses is hands-on. Special \n",
    "    attention will be devoted to applying the methodologies introduced in class on empirical data using Jupyter notebooks coded in either \n",
    "    Python or R. Overall, the courses of the BSE Summer School in Data Science give participants the tools to apply modern machine learning \n",
    "    techniques, from data exploration to building predictive models and extracting insights. Presenters: Déborah Sulem (UPF and BSE),\n",
    "    André B.M. Souza (ESADE), Hannes Mueller (IAE-CSIC and BSE), and Lorenzo Cappello (UPF and BSE) \"\"\"},\n",
    "\n",
    "    'bse_labor': {'intro':\n",
    "    \"\"\"This summer school is held at the Barcelona School of Economics. Labor related issues have been studied in the economics profession from a number of different angles. The BSE \n",
    "    Labor Economics Summer School covers a wide range of topics in labor economics from a variety of perspectives. In particular, this summer \n",
    "    school offers courses that will cover recent developments within the macro-labor and micro-labor contexts. In each course, both \n",
    "    theoretical and empirical aspects will be covered as well as economic policy. These courses should be of interest to graduate students \n",
    "    or academics who want to expand their knowledge in the area and to practitioners interested in understanding the fundamentals of these \n",
    "    issues. During the courses, faculty are available to discuss research ideas and projects with the program participants. After attending \n",
    "    any of the courses offered at the labor summer school, students will have a 360 degree view of the topic studied and be up to date with \n",
    "    the latest advancements. Presenters: Derek Neal (University of Chicago), Libertad González (UPF and BSE), Joan Llull (IAE-CSIC and BSE)\"\"\"},\n",
    "     \n",
    "    'cemfi_metrics':{'intro':\n",
    "    \"\"\"This summer school is held at CEMFI in Madrid. In recent years there has been an upsurge of interest in new methods for the analysis of matched employer-employee \n",
    "    data to study the labor market, partly motivated by the increasing availability of this type of datasets. Existing methods are also \n",
    "    finding applicability in other areas such as international trade, economic geography, environmental economics or intergenerational \n",
    "    mobility. A main theme is how to deal with multiple heterogeneities and their potential interactions. This course will introduce newly \n",
    "    developed approaches to deal with unobserved heterogeneity in conventional and matched panel data sets with an emphasis on \n",
    "    discrete-classification methods. It will also provide an overview of traditional methods to decompose earnings variability into worker\n",
    "     and firm-level effects as well as the more recent distributional approaches. Finally, the course will review methods for studying \n",
    "     transitions and dynamic responses. Presenter: Elena Manresa (New York University)\"\"\"},\n",
    "     \n",
    "    'cage_research_training':{'intro':\n",
    "    \"\"\"This summer school is held at the University of Warwick. The summer school will cover the following topics: - Coding for Economists: Organising a professional coding \n",
    "    workflow using Github and Python. Data Management and Analysis: Case studies on how to put together complex repeated cross-section and \n",
    "    panel datasets, along with how to present and analyse them. Digitisation of Historical Data: Converting hard copy tabular and text data \n",
    "    into electronic form. How to employ OCR (Optical Character Recognition) tools and what you can do when those methods won’t work. How to \n",
    "    use GIS (Geographic Information System) techniques to extract spatial data from maps. Using non-standard approaches to measure historical \n",
    "    phenomena. Working on the Cloud: Your desktop machine is too slow so you have to move to cloud computing. We’ll provide a guide to setting\n",
    "    up and running big data analysis on Amazon Web Services (AWS). Using LLMs in Economics Research: Large-language Models are all the rage.\n",
    "    We’ll show how they can be used to build new types of data, for example, the codification of large text databases into a structured form. \n",
    "    Research Design: Faculty will present examples of their research and go under the surface to show the data construction, analysis and \n",
    "    workflows that were involved in putting together a paper. Data Visualisation: How to build creative and well-designed data visualisations. \n",
    "    The timetable of the summer school will be organised around lectures in the first half of the day with research presentations / case \n",
    "    studies in the second half. There’ll also be chances for hands-on and participatory work by students in the afternoon sessions. Organiser:\n",
    "     Professor Mirko Draca, University of Warwick (CAGE Director) Lecturers/Presenters: Arthur Turrell (Bank of England), Eric Melander \n",
    "     (Birmingham), Peter John Lambert (LSE), Marie Segger (The Economist magazine).\"\"\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "# We use Open AI Emeddings\n",
    "# First we compute the embedding for each introduction\n",
    "# We then find the course most similar to ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that takes in the text and return an openai embedding\n",
    "def get_openai_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    # use the openai api to create an embedding\n",
    "    response = client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "    # return the embedding\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for bse_data_science saved successfully!\n",
      "Embedding for bse_labor saved successfully!\n",
      "Embedding for cemfi_metrics saved successfully!\n",
      "Embedding for cage_research_training saved successfully!\n"
     ]
    }
   ],
   "source": [
    "for summer_school_name, summer_school_data in summer_school_introductions.items():\n",
    "    # get the embedding\n",
    "    embedding = get_openai_embedding(summer_school_data['intro'])\n",
    "    # save the embedding\n",
    "    summer_school_data['embedding'] = embedding\n",
    "    print(f\"Embedding for {summer_school_name} saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.002228632802143693,\n",
       " 0.03856687247753143,\n",
       " -0.01582929864525795,\n",
       " 0.023854326456785202,\n",
       " -0.018945815041661263,\n",
       " -0.00763546209782362,\n",
       " 0.026983825489878654,\n",
       " 0.0251658596098423,\n",
       " -0.01152461301535368,\n",
       " -0.01507614180445671,\n",
       " -0.011258410289883614,\n",
       " -0.04848777875304222,\n",
       " 0.030048400163650513,\n",
       " -0.05212371423840523,\n",
       " 0.03545035794377327,\n",
       " 0.00708357896655798,\n",
       " -0.0007547810091637075,\n",
       " -0.008615865372121334,\n",
       " -0.005612973589450121,\n",
       " -0.011816786602139473,\n",
       " -0.0009657950140535831,\n",
       " -0.006022016052156687,\n",
       " -0.005509089678525925,\n",
       " 0.026698146015405655,\n",
       " -0.009589776396751404,\n",
       " 0.010953252203762531,\n",
       " 0.013388029299676418,\n",
       " 0.005710364785045385,\n",
       " -0.030100341886281967,\n",
       " 0.027996692806482315,\n",
       " 0.019543146714568138,\n",
       " 0.042800139635801315,\n",
       " 0.035294532775878906,\n",
       " -0.07012158632278442,\n",
       " -0.010609136894345284,\n",
       " -0.036411285400390625,\n",
       " -0.00846004020422697,\n",
       " -0.008946995250880718,\n",
       " -0.008875574916601181,\n",
       " 0.047786563634872437,\n",
       " 0.0026100813411176205,\n",
       " 0.015387793071568012,\n",
       " 0.003681383328512311,\n",
       " 0.0003550717083271593,\n",
       " 0.01572541519999504,\n",
       " -0.013186754658818245,\n",
       " -0.0017530397744849324,\n",
       " -0.042904023081064224,\n",
       " -0.026905912905931473,\n",
       " -0.02434777468442917,\n",
       " 0.002528922166675329,\n",
       " 0.0310872383415699,\n",
       " 0.016803210601210594,\n",
       " -0.008245779201388359,\n",
       " -0.032437726855278015,\n",
       " 0.008063982240855694,\n",
       " 0.06165505573153496,\n",
       " 0.027996692806482315,\n",
       " 0.0029769211541861296,\n",
       " -0.02877582237124443,\n",
       " -0.008966473862528801,\n",
       " -0.011128555983304977,\n",
       " -0.04415062814950943,\n",
       " -0.0334765650331974,\n",
       " 0.0579671785235405,\n",
       " 0.009375516325235367,\n",
       " 0.01116101909428835,\n",
       " 0.0340479277074337,\n",
       " -0.011394757777452469,\n",
       " 0.0027512984815984964,\n",
       " 0.0008740850607864559,\n",
       " -0.0018017352558672428,\n",
       " -0.019504189491271973,\n",
       " 0.023984180763363838,\n",
       " 0.023360878229141235,\n",
       " 0.014309998601675034,\n",
       " -0.008537952788174152,\n",
       " -0.014154172502458096,\n",
       " -0.0523834228515625,\n",
       " 0.0027561679016798735,\n",
       " 0.010005312040448189,\n",
       " -0.049630504101514816,\n",
       " 0.03654113784432411,\n",
       " 0.027061739936470985,\n",
       " 0.012589422054588795,\n",
       " -0.005681147333234549,\n",
       " -0.0024607484228909016,\n",
       " -0.06134340539574623,\n",
       " 0.0022886907681822777,\n",
       " 0.0167382825165987,\n",
       " -0.02201038785278797,\n",
       " -0.0006358827231451869,\n",
       " -0.006694014649838209,\n",
       " -0.021036475896835327,\n",
       " -0.02276354469358921,\n",
       " 0.020945578813552856,\n",
       " -0.014660606160759926,\n",
       " 0.0017433005850762129,\n",
       " 0.018257584422826767,\n",
       " -0.00929760280996561,\n",
       " 0.0207248255610466,\n",
       " 0.010135166347026825,\n",
       " -0.037242356687784195,\n",
       " -0.033372681587934494,\n",
       " -0.00162480806466192,\n",
       " -0.010368905030190945,\n",
       " -0.03184039518237114,\n",
       " 0.02552945166826248,\n",
       " -0.01712784729897976,\n",
       " 0.05516231805086136,\n",
       " -0.023153109475970268,\n",
       " -0.02906150370836258,\n",
       " -0.03300908952951431,\n",
       " 0.03332073986530304,\n",
       " -0.05370794236660004,\n",
       " 0.044929757714271545,\n",
       " -0.024841222912073135,\n",
       " 0.014037303626537323,\n",
       " 0.020932592451572418,\n",
       " -0.00860287994146347,\n",
       " 0.00030150660313665867,\n",
       " -0.039917364716529846,\n",
       " 0.010914294980466366,\n",
       " 0.006220044568181038,\n",
       " -0.02230905368924141,\n",
       " 0.036515168845653534,\n",
       " -0.04524141177535057,\n",
       " 0.05775941163301468,\n",
       " -0.004944221116602421,\n",
       " -0.004518946632742882,\n",
       " 0.03007437102496624,\n",
       " 0.01951717585325241,\n",
       " -0.01682918146252632,\n",
       " -0.023205051198601723,\n",
       " -0.029944514855742455,\n",
       " 0.009037893265485764,\n",
       " 0.0149462865665555,\n",
       " 0.041605476289987564,\n",
       " -0.008005548268556595,\n",
       " -0.029373154044151306,\n",
       " -0.021452011540532112,\n",
       " -0.002280574757605791,\n",
       " -0.0013983738608658314,\n",
       " -0.019647030159831047,\n",
       " -0.00782375130802393,\n",
       " -0.07536771893501282,\n",
       " 0.00319118145853281,\n",
       " 0.0075705344788730145,\n",
       " 0.03119112178683281,\n",
       " 0.012751740403473377,\n",
       " 0.004648801404982805,\n",
       " 0.03303505852818489,\n",
       " 0.0266462042927742,\n",
       " -0.0008927517337724566,\n",
       " 0.023101167753338814,\n",
       " 0.017413528636097908,\n",
       " -0.04170935973525047,\n",
       " -0.001824459875933826,\n",
       " -0.01082989014685154,\n",
       " 0.024763308465480804,\n",
       " 0.014361940324306488,\n",
       " 0.020140478387475014,\n",
       " 0.014699562452733517,\n",
       " 0.009427458047866821,\n",
       " -0.01175185851752758,\n",
       " -0.02043914422392845,\n",
       " -0.015063156373798847,\n",
       " -0.028204461559653282,\n",
       " -0.015595560893416405,\n",
       " 0.029217328876256943,\n",
       " -0.0013026058441028,\n",
       " -0.01655648648738861,\n",
       " -0.019569117575883865,\n",
       " -0.015128083527088165,\n",
       " 0.01342698559165001,\n",
       " -0.01637468859553337,\n",
       " 0.024399716407060623,\n",
       " -0.024581512436270714,\n",
       " -0.04106008633971214,\n",
       " -0.007077086251229048,\n",
       " -0.016309762373566628,\n",
       " 0.03796954080462456,\n",
       " 0.004837091080844402,\n",
       " 0.006359638646245003,\n",
       " -0.027529215440154076,\n",
       " 0.0012888088822364807,\n",
       " 0.035580214112997055,\n",
       " -0.05817494913935661,\n",
       " 0.008654821664094925,\n",
       " -0.0006338537205010653,\n",
       " -0.010407861322164536,\n",
       " 0.007797780446708202,\n",
       " -0.019595088437199593,\n",
       " -0.011914177797734737,\n",
       " 0.0065479278564453125,\n",
       " -0.009901427663862705,\n",
       " -0.010628614574670792,\n",
       " 0.018478337675333023,\n",
       " 0.030671702697873116,\n",
       " -0.003674890613183379,\n",
       " -0.0384889617562294,\n",
       " -0.057603586465120316,\n",
       " 0.0021783141419291496,\n",
       " 0.01521898154169321,\n",
       " 0.022049343213438988,\n",
       " -0.00031428918009623885,\n",
       " 0.008148388005793095,\n",
       " 0.004376106429845095,\n",
       " -0.017413528636097908,\n",
       " -0.04952661693096161,\n",
       " 0.004931235685944557,\n",
       " -0.026217682287096977,\n",
       " -0.009193719364702702,\n",
       " 0.032905206084251404,\n",
       " -0.020581984892487526,\n",
       " -0.013115334324538708,\n",
       " 0.004450772888958454,\n",
       " 0.006434305105358362,\n",
       " 0.010758469812572002,\n",
       " -0.012420611456036568,\n",
       " 0.011050643399357796,\n",
       " 0.0011354178423061967,\n",
       " 0.03072364442050457,\n",
       " 0.019504189491271973,\n",
       " -0.023386849090456963,\n",
       " 0.010427339933812618,\n",
       " 0.016868136823177338,\n",
       " -0.04093023017048836,\n",
       " 0.004226773511618376,\n",
       " -0.011031164787709713,\n",
       " -0.004213788080960512,\n",
       " 0.005781784653663635,\n",
       " 0.0006131581030786037,\n",
       " -0.03898240998387337,\n",
       " -0.02543855458498001,\n",
       " 0.0360996313393116,\n",
       " -0.0034119347110390663,\n",
       " 0.0012222582008689642,\n",
       " -0.016907094046473503,\n",
       " -0.02046511508524418,\n",
       " 0.013115334324538708,\n",
       " -0.023750441148877144,\n",
       " -0.01664738543331623,\n",
       " 0.015582575462758541,\n",
       " -0.012991972267627716,\n",
       " -0.029944514855742455,\n",
       " 0.019828826189041138,\n",
       " 0.03306103125214577,\n",
       " 0.015167039819061756,\n",
       " 0.02628261037170887,\n",
       " -0.009252154268324375,\n",
       " -0.0331389419734478,\n",
       " -0.001968923257663846,\n",
       " -0.010472789406776428,\n",
       " -0.0033794709015637636,\n",
       " 0.003697615349665284,\n",
       " 0.017621295526623726,\n",
       " -0.01766025274991989,\n",
       " 0.00580450939014554,\n",
       " 0.007531578186899424,\n",
       " 0.0012920552399009466,\n",
       " -0.030515875667333603,\n",
       " -0.0007304332102648914,\n",
       " 0.013478927314281464,\n",
       " -0.00836914125829935,\n",
       " -0.03680085018277168,\n",
       " 0.03184039518237114,\n",
       " -0.010109195485711098,\n",
       " -0.029658835381269455,\n",
       " -0.027711013332009315,\n",
       " -0.04479990527033806,\n",
       " -0.015465705655515194,\n",
       " 0.04542320594191551,\n",
       " 0.004379353020340204,\n",
       " -0.0034930938854813576,\n",
       " 0.0008659691666252911,\n",
       " 0.037424150854349136,\n",
       " -0.006986187770962715,\n",
       " -0.002676632022485137,\n",
       " 0.05895407497882843,\n",
       " 0.038540903478860855,\n",
       " -0.021166332066059113,\n",
       " 0.028568055480718613,\n",
       " -0.026905912905931473,\n",
       " -0.01895879954099655,\n",
       " 0.018452366814017296,\n",
       " -0.0002822312817443162,\n",
       " -0.030567819252610207,\n",
       " 0.025386612862348557,\n",
       " -0.03259355202317238,\n",
       " 0.01133632380515337,\n",
       " -0.016050051897764206,\n",
       " -0.016504544764757156,\n",
       " 0.08243182301521301,\n",
       " 0.031035296618938446,\n",
       " 0.0002546371251810342,\n",
       " -0.02173769287765026,\n",
       " 0.005742828361690044,\n",
       " -0.034853026270866394,\n",
       " 0.006505724973976612,\n",
       " 0.041423678398132324,\n",
       " 0.04035887122154236,\n",
       " 0.012550465762615204,\n",
       " -0.0195301603525877,\n",
       " 0.014154172502458096,\n",
       " 0.008453547023236752,\n",
       " -0.0010777948191389441,\n",
       " 0.04061857983469963,\n",
       " -0.010057253763079643,\n",
       " -0.009674182161688805,\n",
       " 0.01747845485806465,\n",
       " 0.02395820990204811,\n",
       " 0.02525675669312477,\n",
       " -0.01554361917078495,\n",
       " 0.021893518045544624,\n",
       " 0.022594735026359558,\n",
       " 0.0264773927628994,\n",
       " -0.0028973850421607494,\n",
       " 0.003330775536596775,\n",
       " -0.015673473477363586,\n",
       " 0.017088890075683594,\n",
       " 0.019763899967074394,\n",
       " -0.026308581233024597,\n",
       " 0.056408923119306564,\n",
       " 0.02591901645064354,\n",
       " -0.028645968064665794,\n",
       " 0.00638236291706562,\n",
       " -0.015465705655515194,\n",
       " 0.07282257080078125,\n",
       " 0.008193837478756905,\n",
       " -0.018010860309004784,\n",
       " -0.014141187071800232,\n",
       " -0.07022546976804733,\n",
       " -0.006739463657140732,\n",
       " 0.08035414665937424,\n",
       " -0.07079683244228363,\n",
       " -0.010187109000980854,\n",
       " 0.01981584168970585,\n",
       " 0.0024299079086631536,\n",
       " -0.02739936113357544,\n",
       " 0.008921024389564991,\n",
       " -0.005979813169687986,\n",
       " -0.03277534991502762,\n",
       " 0.021958446130156517,\n",
       " -0.02867193892598152,\n",
       " 0.005716857500374317,\n",
       " 0.01608900912106037,\n",
       " -0.012277770787477493,\n",
       " 0.029918543994426727,\n",
       " 0.018543263897299767,\n",
       " 0.0006488681538030505,\n",
       " 0.011485656723380089,\n",
       " 0.004174831788986921,\n",
       " 0.01003777515143156,\n",
       " 0.025412583723664284,\n",
       " -0.04404674470424652,\n",
       " -0.018179671838879585,\n",
       " -0.02786683849990368,\n",
       " 0.01467359159141779,\n",
       " 0.0004788395599462092,\n",
       " 0.0316585972905159,\n",
       " -0.021711722016334534,\n",
       " -0.004522193223237991,\n",
       " -0.0010445194784551859,\n",
       " -0.026776058599352837,\n",
       " 0.01749144122004509,\n",
       " -0.0015436488902196288,\n",
       " -0.018660133704543114,\n",
       " -0.00210364768281579,\n",
       " 0.02784086763858795,\n",
       " -0.04757879674434662,\n",
       " 0.016153937205672264,\n",
       " 0.053240466862916946,\n",
       " -0.04170935973525047,\n",
       " 0.00786920078098774,\n",
       " -0.0119011914357543,\n",
       " -0.01860819198191166,\n",
       " 0.02867193892598152,\n",
       " -0.01610199362039566,\n",
       " -0.003798252670094371,\n",
       " -0.010388383641839027,\n",
       " 0.004648801404982805,\n",
       " 0.010213079862296581,\n",
       " 0.06658954173326492,\n",
       " 0.02332192100584507,\n",
       " 0.013336087577044964,\n",
       " -0.007330303080379963,\n",
       " 0.021542910486459732,\n",
       " 0.0016702573047950864,\n",
       " 0.015946168452501297,\n",
       " -0.01068055722862482,\n",
       " -0.039943333715200424,\n",
       " -0.027970721945166588,\n",
       " -0.03137291967868805,\n",
       " 0.011790815740823746,\n",
       " -0.003996281418949366,\n",
       " -0.019322393462061882,\n",
       " -0.0038079917430877686,\n",
       " 0.011673945933580399,\n",
       " 0.04581277072429657,\n",
       " -0.051214732229709625,\n",
       " 0.0018910104408860207,\n",
       " 0.007927634753286839,\n",
       " 0.03324282541871071,\n",
       " 0.004619584418833256,\n",
       " -0.023750441148877144,\n",
       " 0.03950182721018791,\n",
       " -0.034021954983472824,\n",
       " 0.006596623454242945,\n",
       " -0.00649923225864768,\n",
       " -0.035943806171417236,\n",
       " -0.036229487508535385,\n",
       " -0.0007052738219499588,\n",
       " -0.009180733934044838,\n",
       " -0.021867547184228897,\n",
       " 0.047422971576452255,\n",
       " 0.029009560123085976,\n",
       " 0.002975297858938575,\n",
       " 0.02555542252957821,\n",
       " 0.01785503327846527,\n",
       " 0.030957382172346115,\n",
       " -0.01355684082955122,\n",
       " -0.010894817300140858,\n",
       " 0.03202219307422638,\n",
       " 0.007440679706633091,\n",
       " 0.02682800032198429,\n",
       " 0.015296895056962967,\n",
       " -0.034827057272195816,\n",
       " -0.007161492016166449,\n",
       " -0.007038129959255457,\n",
       " 0.0120700029656291,\n",
       " 0.050383660942316055,\n",
       " -0.04534529522061348,\n",
       " 0.015387793071568012,\n",
       " 0.04924093931913376,\n",
       " -0.009382008574903011,\n",
       " 0.026802029460668564,\n",
       " 0.023269979283213615,\n",
       " 0.0029769211541861296,\n",
       " -0.00938850175589323,\n",
       " -0.014089245349168777,\n",
       " -0.051604293286800385,\n",
       " 0.02238696627318859,\n",
       " -0.013056899420917034,\n",
       " -0.03682681918144226,\n",
       " -0.04757879674434662,\n",
       " -0.003140862798318267,\n",
       " 0.0360996313393116,\n",
       " 0.03332073986530304,\n",
       " 0.008641836233437061,\n",
       " -0.012823160737752914,\n",
       " -0.002871414180845022,\n",
       " -0.050955019891262054,\n",
       " 0.0026311827823519707,\n",
       " 0.03238578513264656,\n",
       " -0.038644786924123764,\n",
       " 0.019867783412337303,\n",
       " -0.004038484301418066,\n",
       " 0.022919371724128723,\n",
       " 0.026529334485530853,\n",
       " -0.0222051702439785,\n",
       " 0.048254042863845825,\n",
       " 0.014985242858529091,\n",
       " -0.011719395406544209,\n",
       " 0.0034638766665011644,\n",
       " 0.014894344843924046,\n",
       " -0.03773580491542816,\n",
       " 0.003186312038451433,\n",
       " -0.003171703312546015,\n",
       " 0.021724706515669823,\n",
       " 0.006323928479105234,\n",
       " -0.020971549674868584,\n",
       " -0.015608546324074268,\n",
       " 0.036774877458810806,\n",
       " 0.0038794120773673058,\n",
       " 0.019556131213903427,\n",
       " -0.017919961363077164,\n",
       " -0.003593731438741088,\n",
       " 0.003421673784032464,\n",
       " -0.017049934715032578,\n",
       " -0.03025616705417633,\n",
       " -0.024841222912073135,\n",
       " 0.026698146015405655,\n",
       " -0.025152873247861862,\n",
       " -0.01078444067388773,\n",
       " -0.008031519129872322,\n",
       " 0.022802501916885376,\n",
       " 0.021114390343427658,\n",
       " -0.013297131285071373,\n",
       " 0.039190176874399185,\n",
       " -0.001975415972992778,\n",
       " 0.027892809361219406,\n",
       " 0.0013415623689070344,\n",
       " -0.008466532453894615,\n",
       " -0.008810647763311863,\n",
       " -0.010693542659282684,\n",
       " 0.03472317010164261,\n",
       " 0.005606480874121189,\n",
       " -0.0009308965527452528,\n",
       " -0.021763663738965988,\n",
       " -0.04248848930001259,\n",
       " 0.00381773104891181,\n",
       " 0.011881713755428791,\n",
       " 0.035034824162721634,\n",
       " -0.004661787301301956,\n",
       " -0.025581395253539085,\n",
       " -0.003528804052621126,\n",
       " 0.02081572264432907,\n",
       " -0.008174358867108822,\n",
       " 0.020244361832737923,\n",
       " 0.06466768682003021,\n",
       " 0.0044410340487957,\n",
       " -0.02590603195130825,\n",
       " -0.024945106357336044,\n",
       " 0.012940030544996262,\n",
       " -0.007414708845317364,\n",
       " 0.013336087577044964,\n",
       " 0.024477628991007805,\n",
       " 0.003593731438741088,\n",
       " 0.01216090191155672,\n",
       " 0.0006042305612936616,\n",
       " -0.024386730045080185,\n",
       " 0.005249380134046078,\n",
       " 0.025100931525230408,\n",
       " -0.02823043242096901,\n",
       " -0.010641600005328655,\n",
       " 0.0019283436704427004,\n",
       " 0.009589776396751404,\n",
       " 0.0023227776400744915,\n",
       " -0.0514744408428669,\n",
       " -0.025321684777736664,\n",
       " 0.02091960795223713,\n",
       " 0.0029817908070981503,\n",
       " 0.005953842308372259,\n",
       " 0.03880061209201813,\n",
       " 0.028801793232560158,\n",
       " -0.009830008260905743,\n",
       " -0.017556367442011833,\n",
       " 0.0031781960278749466,\n",
       " -0.004561149515211582,\n",
       " -0.035294532775878906,\n",
       " 0.004518946632742882,\n",
       " -0.013349073007702827,\n",
       " -0.014959271997213364,\n",
       " -0.011829772032797337,\n",
       " 0.01563451811671257,\n",
       " 0.0562530979514122,\n",
       " -0.005781784653663635,\n",
       " 0.02395820990204811,\n",
       " -0.030308108776807785,\n",
       " -0.005694132763892412,\n",
       " -0.018257584422826767,\n",
       " -0.01756935380399227,\n",
       " 0.015361822210252285,\n",
       " 0.007797780446708202,\n",
       " -0.006745956372469664,\n",
       " -0.037995513528585434,\n",
       " 0.01124542485922575,\n",
       " 0.01231023482978344,\n",
       " -0.008356155827641487,\n",
       " -0.00048736127791926265,\n",
       " -0.04750088229775429,\n",
       " 0.011232439428567886,\n",
       " -0.011355801485478878,\n",
       " -0.040852319449186325,\n",
       " -0.009667688980698586,\n",
       " 0.008122417144477367,\n",
       " 0.035112734884023666,\n",
       " -0.009674182161688805,\n",
       " 0.015063156373798847,\n",
       " -0.004648801404982805,\n",
       " 0.017153818160295486,\n",
       " 0.005440915934741497,\n",
       " -0.005207177251577377,\n",
       " -0.00981052964925766,\n",
       " 0.060096800327301025,\n",
       " -0.006463522557169199,\n",
       " 0.013154290616512299,\n",
       " -0.006557667162269354,\n",
       " -0.02423090487718582,\n",
       " -0.017049934715032578,\n",
       " 0.0052948291413486,\n",
       " -0.012466059997677803,\n",
       " 0.005275350995361805,\n",
       " 0.020244361832737923,\n",
       " 0.0134659418836236,\n",
       " 0.0316585972905159,\n",
       " -0.003853440983220935,\n",
       " 0.0016913587460294366,\n",
       " 0.018945815041661263,\n",
       " -0.04069649428129196,\n",
       " 0.020750796422362328,\n",
       " -0.009875456802546978,\n",
       " 0.011511627584695816,\n",
       " 0.018270568922162056,\n",
       " 0.026139769703149796,\n",
       " -0.01541376393288374,\n",
       " -0.026074843481183052,\n",
       " -0.006797898560762405,\n",
       " 0.0006391290808096528,\n",
       " 0.02034824714064598,\n",
       " 0.02489316463470459,\n",
       " -0.018621178343892097,\n",
       " 0.005116278771311045,\n",
       " 0.007414708845317364,\n",
       " 0.01379057951271534,\n",
       " 0.01933537796139717,\n",
       " -0.02286743000149727,\n",
       " -0.03352850675582886,\n",
       " 0.005765552632510662,\n",
       " 0.05957737937569618,\n",
       " -0.00012995624274481088,\n",
       " -0.00575905991718173,\n",
       " -0.011414236389100552,\n",
       " 0.0399693064391613,\n",
       " -0.02942509576678276,\n",
       " 0.0043501355685293674,\n",
       " 0.011836264282464981,\n",
       " 0.02451658435165882,\n",
       " -0.012940030544996262,\n",
       " 0.03259355202317238,\n",
       " 0.0047754100523889065,\n",
       " -0.019569117575883865,\n",
       " -0.01281017530709505,\n",
       " 0.009680675342679024,\n",
       " 0.002423415193334222,\n",
       " 0.018348481506109238,\n",
       " 0.014180143363773823,\n",
       " -0.009985833428800106,\n",
       " -0.0024656178429722786,\n",
       " -0.010537716560065746,\n",
       " 0.010213079862296581,\n",
       " 0.022893400862812996,\n",
       " -0.0025240525137633085,\n",
       " -0.013173769228160381,\n",
       " 0.028360286727547646,\n",
       " -0.0016670109471306205,\n",
       " 0.035502299666404724,\n",
       " 0.0023812123108655214,\n",
       " -0.015699444338679314,\n",
       " 0.0028340809512883425,\n",
       " -0.0016702573047950864,\n",
       " -0.029554951936006546,\n",
       " 0.05542202666401863,\n",
       " -0.0020679375156760216,\n",
       " 0.0030012689530849457,\n",
       " -0.008304214105010033,\n",
       " -0.0019543147645890713,\n",
       " -0.01004426833242178,\n",
       " 0.012342697940766811,\n",
       " -0.008998936973512173,\n",
       " 0.015530633740127087,\n",
       " -0.006476507987827063,\n",
       " 0.012362176552414894,\n",
       " 0.004415063187479973,\n",
       " -0.007836736738681793,\n",
       " -0.005444162059575319,\n",
       " -0.014348954893648624,\n",
       " -0.024854207411408424,\n",
       " 0.009823515079915524,\n",
       " -0.030775586143136024,\n",
       " 0.0022692126221954823,\n",
       " 0.0007077086484059691,\n",
       " -0.0038372091948986053,\n",
       " -0.0014770983252674341,\n",
       " -0.012063510715961456,\n",
       " -0.006112914532423019,\n",
       " 0.00953134149312973,\n",
       " -0.0011735627194866538,\n",
       " -0.006077204365283251,\n",
       " 0.021711722016334534,\n",
       " -0.02572423405945301,\n",
       " -0.02108841761946678,\n",
       " -0.003103529568761587,\n",
       " -0.019673001021146774,\n",
       " -0.01676425337791443,\n",
       " -0.006379116792231798,\n",
       " -0.006557667162269354,\n",
       " 0.013647738844156265,\n",
       " 0.028801793232560158,\n",
       " 0.010115688666701317,\n",
       " -0.0119855972006917,\n",
       " 0.0020013870671391487,\n",
       " -0.0431637316942215,\n",
       " 0.015959154814481735,\n",
       " -0.010472789406776428,\n",
       " -0.015465705655515194,\n",
       " 0.044358398765325546,\n",
       " -0.01703694835305214,\n",
       " -0.006797898560762405,\n",
       " 0.0035190649796277285,\n",
       " -0.034567344933748245,\n",
       " 0.02765907160937786,\n",
       " -0.008044504560530186,\n",
       " 0.010427339933812618,\n",
       " -0.006460275966674089,\n",
       " -0.005184452515095472,\n",
       " 0.012505016289651394,\n",
       " 0.002679878380149603,\n",
       " 0.0020987780299037695,\n",
       " 0.018932828679680824,\n",
       " -0.011511627584695816,\n",
       " -0.011466178111732006,\n",
       " 0.009609255008399487,\n",
       " 0.04924093931913376,\n",
       " 0.045760829001665115,\n",
       " -0.008154881186783314,\n",
       " 0.010641600005328655,\n",
       " 0.008615865372121334,\n",
       " 0.035476330667734146,\n",
       " 0.00846004020422697,\n",
       " -0.028100578114390373,\n",
       " 0.04430645704269409,\n",
       " -0.012336205691099167,\n",
       " 0.015959154814481735,\n",
       " -0.017062919214367867,\n",
       " 0.013388029299676418,\n",
       " -0.006096682511270046,\n",
       " -0.020491085946559906,\n",
       " 0.029373154044151306,\n",
       " 0.012849131599068642,\n",
       " -0.003898890223354101,\n",
       " -0.03745012357831001,\n",
       " -0.020763780921697617,\n",
       " -0.027451302856206894,\n",
       " 0.008635343983769417,\n",
       " -0.016699327155947685,\n",
       " 0.0020095028448849916,\n",
       " -0.027373390272259712,\n",
       " 0.000724752084352076,\n",
       " 0.00324961612932384,\n",
       " 0.018283555284142494,\n",
       " -0.028827764093875885,\n",
       " 0.017270687967538834,\n",
       " 0.04394286125898361,\n",
       " -0.005638944450765848,\n",
       " -0.004161846358329058,\n",
       " -0.011219453997910023,\n",
       " 0.0017838802887126803,\n",
       " 0.0022091546561568975,\n",
       " 0.04939676448702812,\n",
       " -0.051578324288129807,\n",
       " 0.034749142825603485,\n",
       " 0.0024753569159656763,\n",
       " -0.013076378032565117,\n",
       " 0.010485774837434292,\n",
       " 0.02554243803024292,\n",
       " 0.0009317081421613693,\n",
       " 0.032515641301870346,\n",
       " 0.015257937833666801,\n",
       " 0.004528685938566923,\n",
       " -0.027970721945166588,\n",
       " 0.011401250958442688,\n",
       " -0.030308108776807785,\n",
       " -0.04638413339853287,\n",
       " 0.008641836233437061,\n",
       " 0.043553296476602554,\n",
       " -0.018543263897299767,\n",
       " -0.016621412709355354,\n",
       " 0.010810411535203457,\n",
       " -0.003030486172065139,\n",
       " 0.02851611189544201,\n",
       " 0.004869554657489061,\n",
       " -0.010933773592114449,\n",
       " -0.01406327448785305,\n",
       " 0.05646086484193802,\n",
       " 0.018621178343892097,\n",
       " -0.010459803976118565,\n",
       " -0.0005551292560994625,\n",
       " -0.001113504869863391,\n",
       " 0.0034411519300192595,\n",
       " 0.00010865194053621963,\n",
       " 0.040203046053647995,\n",
       " 0.00661610160022974,\n",
       " 0.018361467868089676,\n",
       " 0.010472789406776428,\n",
       " -0.012933537364006042,\n",
       " 0.0006265493575483561,\n",
       " 0.037346240133047104,\n",
       " -0.0018634162843227386,\n",
       " 0.043267618864774704,\n",
       " -0.018010860309004784,\n",
       " 0.013102348893880844,\n",
       " -0.006112914532423019,\n",
       " 0.0007872447022236884,\n",
       " -0.000678897078614682,\n",
       " 0.010758469812572002,\n",
       " -0.00024002847203519195,\n",
       " -0.007927634753286839,\n",
       " 0.016608428210020065,\n",
       " 0.015348836779594421,\n",
       " -0.016816195100545883,\n",
       " -0.018478337675333023,\n",
       " -0.030386021360754967,\n",
       " 0.02285444363951683,\n",
       " -0.01978987082839012,\n",
       " -0.038255222141742706,\n",
       " 0.016322746872901917,\n",
       " -0.011771337129175663,\n",
       " 0.009102821350097656,\n",
       " 0.01888088695704937,\n",
       " 0.008193837478756905,\n",
       " 0.008447054773569107,\n",
       " -0.0223220381885767,\n",
       " 0.007999055087566376,\n",
       " 0.008524967357516289,\n",
       " -0.012803683057427406,\n",
       " -0.03638531267642975,\n",
       " -0.0006837666733190417,\n",
       " -0.006489493418484926,\n",
       " 0.03729429841041565,\n",
       " -0.002761037554591894,\n",
       " 0.0009179110638797283,\n",
       " -0.004100165329873562,\n",
       " 0.008505488745868206,\n",
       " -0.006307696457952261,\n",
       " -0.00708357896655798,\n",
       " 0.005629205144941807,\n",
       " -0.025581395253539085,\n",
       " 0.012563451193273067,\n",
       " 0.02110140398144722,\n",
       " -0.012057017534971237,\n",
       " -0.0024753569159656763,\n",
       " -0.013621767982840538,\n",
       " -0.05230551213026047,\n",
       " 0.0416833870112896,\n",
       " 0.010557195171713829,\n",
       " -0.006489493418484926,\n",
       " 0.008719749748706818,\n",
       " 0.05040962994098663,\n",
       " 0.012128437869250774,\n",
       " 0.02786683849990368,\n",
       " -0.005768799223005772,\n",
       " 0.0062330299988389015,\n",
       " 0.02564632147550583,\n",
       " 0.018374454230070114,\n",
       " -0.0063336677849292755,\n",
       " 0.0025467772502452135,\n",
       " 0.002623066771775484,\n",
       " 0.0405406653881073,\n",
       " 0.01373863685876131,\n",
       " 0.004645555280148983,\n",
       " -6.502884934889153e-05,\n",
       " -0.008382126688957214,\n",
       " 0.010180615819990635,\n",
       " 0.011654467321932316,\n",
       " -0.002905501052737236,\n",
       " -0.016504544764757156,\n",
       " -0.016452603042125702,\n",
       " -0.037060558795928955,\n",
       " 0.007895171642303467,\n",
       " 0.03932003304362297,\n",
       " -0.05046157166361809,\n",
       " 0.021452011540532112,\n",
       " -0.01712784729897976,\n",
       " -0.013108841143548489,\n",
       " -0.014920315705239773,\n",
       " 0.021400069817900658,\n",
       " 0.007615983486175537,\n",
       " -0.01211545243859291,\n",
       " 0.004934482276439667,\n",
       " 0.0009195342427119613,\n",
       " -0.007609490770846605,\n",
       " -0.009369023144245148,\n",
       " -0.012316727079451084,\n",
       " -0.0165694709867239,\n",
       " 0.015348836779594421,\n",
       " -0.04170935973525047,\n",
       " -0.013478927314281464,\n",
       " 0.0027480521239340305,\n",
       " 0.00884311180561781,\n",
       " 0.019478218629956245,\n",
       " 0.0024445164017379284,\n",
       " 0.009823515079915524,\n",
       " 0.002170198131352663,\n",
       " -0.019192539155483246,\n",
       " 0.003110022284090519,\n",
       " 0.00017479673260822892,\n",
       " -0.020867666229605675,\n",
       " -0.01073899120092392,\n",
       " -0.022075314074754715,\n",
       " 0.0028649214655160904,\n",
       " -0.03581395372748375,\n",
       " -0.027814896777272224,\n",
       " 0.013751622289419174,\n",
       " 0.044747963547706604,\n",
       " -0.020114507526159286,\n",
       " -0.011615511029958725,\n",
       " 0.031866367906332016,\n",
       " -0.005739581771194935,\n",
       " -0.016063038259744644,\n",
       " -0.0013732144143432379,\n",
       " -0.006784913130104542,\n",
       " -0.018751032650470734,\n",
       " -0.026776058599352837,\n",
       " 0.0476047657430172,\n",
       " -0.03119112178683281,\n",
       " -0.0030045153107494116,\n",
       " 0.005272104404866695,\n",
       " -0.0004654482763726264,\n",
       " -0.014790461398661137,\n",
       " 0.015790343284606934,\n",
       " 0.0340479277074337,\n",
       " -0.028490141034126282,\n",
       " -0.000395448412746191,\n",
       " -0.024490613490343094,\n",
       " 0.028542084619402885,\n",
       " -0.003622948657721281,\n",
       " 0.0018277062335982919,\n",
       " 0.027685042470693588,\n",
       " 0.006002537906169891,\n",
       " -0.004606598988175392,\n",
       " -0.008343170396983624,\n",
       " -0.004077440593391657,\n",
       " 0.011602525599300861,\n",
       " 0.011258410289883614,\n",
       " -0.01980285532772541,\n",
       " -0.022373981773853302,\n",
       " 0.011628496460616589,\n",
       " 0.005895407870411873,\n",
       " 0.0010834758868440986,\n",
       " -0.02175067737698555,\n",
       " -0.010641600005328655,\n",
       " 0.01350489817559719,\n",
       " -0.0036943689920008183,\n",
       " 0.0006752449553459883,\n",
       " 0.008667807094752789,\n",
       " 0.05142249912023544,\n",
       " -0.0009544327622279525,\n",
       " 0.00763546209782362,\n",
       " 0.0012920552399009466,\n",
       " 0.006041494198143482,\n",
       " -0.00801204051822424,\n",
       " -0.009726123884320259,\n",
       " 0.04454019293189049,\n",
       " 0.026165740564465523,\n",
       " 0.0220363587141037,\n",
       " 0.03412583842873573,\n",
       " -0.024919135496020317,\n",
       " -0.0023779659532010555,\n",
       " 0.008544445037841797,\n",
       " -0.0037463107146322727,\n",
       " 0.0269318837672472,\n",
       " -0.03173651173710823,\n",
       " -0.011388265527784824,\n",
       " -0.00994038488715887,\n",
       " -0.0030905441381037235,\n",
       " -0.009265139698982239,\n",
       " -0.017608309164643288,\n",
       " 0.008382126688957214,\n",
       " -0.009141777642071247,\n",
       " -0.008473025634884834,\n",
       " -0.020244361832737923,\n",
       " -0.020309289917349815,\n",
       " 0.016621412709355354,\n",
       " -0.007317317649722099,\n",
       " -0.04495573043823242,\n",
       " -0.012089481577277184,\n",
       " 0.008005548268556595,\n",
       " 0.03300908952951431,\n",
       " -0.0022156473714858294,\n",
       " 0.00728485407307744,\n",
       " -0.008356155827641487,\n",
       " -0.009245661087334156,\n",
       " 0.05765552818775177,\n",
       " -0.017543382942676544,\n",
       " -0.008174358867108822,\n",
       " -0.0384889617562294,\n",
       " 0.028282374143600464,\n",
       " 0.0018147208029404283,\n",
       " -0.021439027041196823,\n",
       " 0.016634399071335793,\n",
       " 0.025594379752874374,\n",
       " 0.011628496460616589,\n",
       " -0.01989375427365303,\n",
       " -0.0266462042927742,\n",
       " 0.010751976631581783,\n",
       " 0.011888206005096436,\n",
       " -0.02350371703505516,\n",
       " 0.012862117029726505,\n",
       " 0.009037893265485764,\n",
       " 0.0038339628372341394,\n",
       " 0.04080037772655487,\n",
       " 0.01393341924995184,\n",
       " 0.038826584815979004,\n",
       " -0.006086943671107292,\n",
       " -0.0042235273867845535,\n",
       " -0.012414118275046349,\n",
       " -0.002139357617124915,\n",
       " 0.0030921672005206347,\n",
       " -0.015257937833666801,\n",
       " 0.02110140398144722,\n",
       " 0.02120528742671013,\n",
       " -0.02924329973757267,\n",
       " -0.010732498951256275,\n",
       " -0.01916656829416752,\n",
       " 0.007297839503735304,\n",
       " -0.0120700029656291,\n",
       " 0.008862589485943317,\n",
       " -0.011953134089708328,\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is in the response?\n",
    "summer_school_introductions['bse_labor']['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for bse_data_science saved successfully! The similarity is 0.5957509004815569\n",
      "Similarity for bse_labor saved successfully! The similarity is 0.5847748094953801\n",
      "Similarity for cemfi_metrics saved successfully! The similarity is 0.5780245545761664\n",
      "Similarity for cage_research_training saved successfully! The similarity is 0.9999999999999978\n"
     ]
    }
   ],
   "source": [
    "# which summer school is the most similar to the CAGE Research Training Summer School?\n",
    "# import the cosinsimilarity function\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "for summer_school_name, summer_school_data in summer_school_introductions.items():\n",
    "    # get the cosine similarity\n",
    "    similarity = cosine_similarity([summer_school_introductions['cage_research_training']['embedding']],\n",
    "     [summer_school_data['embedding']])[0][0]\n",
    "    # save the similarity\n",
    "    summer_school_data['similarity_to_cage'] = similarity\n",
    "    print(f\"Similarity for {summer_school_name} saved successfully! The similarity is {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to retrive the most relavent pieces of information based on the similarity\n",
    "# the function take in a question text\n",
    "# rank the summer schools based on the similarity to the question\n",
    "# return the name of the summer school with the highest similarity\n",
    "def get_most_relevant_summer_school(question):\n",
    "    # get the embeddings for the question\n",
    "    question_embedding = get_openai_embedding(question)\n",
    "    # make a copy of the summer school introductions\n",
    "    summer_school_introductions_local = summer_school_introductions.copy()\n",
    "    # calculate the similarity\n",
    "    for summer_school_name, summer_school_data in summer_school_introductions_local.items():\n",
    "        # get the cosine similarity\n",
    "        similarity = cosine_similarity([question_embedding], [summer_school_data['embedding']])[0][0]\n",
    "        # save the similarity\n",
    "        summer_school_data['similarity_to_question'] = similarity\n",
    "        print(f\"Similarity for {summer_school_name} saved successfully! The similarity is {similarity}\")\n",
    "    # get the most similar summer school\n",
    "    most_similar_summer_school = max(summer_school_introductions_local, \n",
    "    key=lambda x: summer_school_introductions_local[x]['similarity_to_question'])\n",
    "    # print the name of the most similar summer school\n",
    "    print(f\"The most similar summer school to the question is {most_similar_summer_school}\")\n",
    "    return summer_school_introductions_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for bse_data_science saved successfully! The similarity is 0.2771734247066264\n",
      "Similarity for bse_labor saved successfully! The similarity is 0.5784717746509018\n",
      "Similarity for cemfi_metrics saved successfully! The similarity is 0.45320353353034076\n",
      "Similarity for cage_research_training saved successfully! The similarity is 0.35536586640236817\n",
      "The most similar summer school to the question is bse_labor\n"
     ]
    }
   ],
   "source": [
    "test1 = get_most_relevant_summer_school('I want to study labor economics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for bse_data_science saved successfully! The similarity is 0.46263311676075436\n",
      "Similarity for bse_labor saved successfully! The similarity is 0.2284374469511692\n",
      "Similarity for cemfi_metrics saved successfully! The similarity is 0.2992189377526428\n",
      "Similarity for cage_research_training saved successfully! The similarity is 0.32954973773062074\n",
      "The most similar summer school to the question is bse_data_science\n"
     ]
    }
   ],
   "source": [
    "test2 = get_most_relevant_summer_school('I want to study data science.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for bse_data_science saved successfully! The similarity is 0.42781849733244315\n",
      "Similarity for bse_labor saved successfully! The similarity is 0.24077832250917902\n",
      "Similarity for cemfi_metrics saved successfully! The similarity is 0.28418814722981484\n",
      "Similarity for cage_research_training saved successfully! The similarity is 0.38982762345272753\n",
      "The most similar summer school to the question is bse_data_science\n"
     ]
    }
   ],
   "source": [
    "test3 = get_most_relevant_summer_school('I want to study data science in the UK.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the embeddings to find the most similar summer school to a given question\n",
    "# define a function that takes in a question and returns an answer\n",
    "# first use the get_most_relevant_summer_school to retrive the ranking of the most relavanet summer schools, \n",
    "# then return the introduction of the most relevant 2 summer schools\n",
    "# then use the openai api to get the answer to the question\n",
    "def get_summer_school_introduction(question):\n",
    "    # get the most relevant summer schools\n",
    "    most_relevant_summer_schools = get_most_relevant_summer_school(question)\n",
    "    # get the introduction of the most relevant summer schools\n",
    "    summer_school_introductions_relavent = {k: v for k, v in most_relevant_summer_schools.items() if v['similarity_to_question'] > 0.3}\n",
    "    # return the introduction of the most relevant summer schools\n",
    "    # prepare the context\n",
    "    # add the summer school introductions to the context of the question\n",
    "    context = ''\n",
    "    for summer_school_name, summer_school_data in summer_school_introductions_relavent.items():\n",
    "        context = context + \"Summer School Name: \"+f\"{summer_school_name}\" + \" Introduction: \"+f\"{summer_school_data['intro']}\"\n",
    "    \n",
    "    #print(context)\n",
    "\n",
    "    #define the question promt\n",
    "    question_prompt = f\"\"\"Question: {question}\n",
    "    Context: The introduction of the most relevant summer schools to the question is as follows: {context}\n",
    "    Please answer the question and explain your reasoning briefly.\n",
    "    \"\"\"\n",
    "    #print(question_prompt)\n",
    "\n",
    "    # get the answer using an openai api call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": question_prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    #return response\n",
    "    print('#####################This is the GPT output.#########################')\n",
    "    print('\\n'.join(textwrap.wrap(response.choices[0].message.content, 100, break_long_words=False)))\n",
    "    print('#####################This is the GPT output.#########################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for bse_data_science saved successfully! The similarity is 0.46263311676075436\n",
      "Similarity for bse_labor saved successfully! The similarity is 0.2284374469511692\n",
      "Similarity for cemfi_metrics saved successfully! The similarity is 0.2992189377526428\n",
      "Similarity for cage_research_training saved successfully! The similarity is 0.32954973773062074\n",
      "The most similar summer school to the question is bse_data_science\n",
      "#####################This is the GPT output.#########################\n",
      "If you want to study data science, the BSE Data Science Summer School at the Barcelona School of\n",
      "Economics is the most relevant choice for you.   **Reasoning:** 1. **Focused on Data Science:** The\n",
      "program specifically offers courses on data science methodologies and machine learning tools, such\n",
      "as \"Foundations of Data Science\" and advanced courses like \"Harnessing Language Models: Your Path to\n",
      "NLP Expert\" and \"Statistical Machine Learning for Large and Unstructured Data.\" 2. **Hands-on\n",
      "Learning:** The BSE program emphasizes practical learning with a hands-on approach using Jupyter\n",
      "notebooks coded in Python or R, which is essential for gaining practical skills in data science. 3.\n",
      "**Comprehensive Coverage:** The program covers a wide range of modern data science techniques, from\n",
      "data exploration to building predictive models and extracting insights.  In contrast, while the CAGE\n",
      "Research Training Summer School at the University of Warwick does cover some relevant topics such as\n",
      "coding, data management, and big data analysis, its focus is broader and includes economic research,\n",
      "historical data digitization, and data visualization, which may be less directly relevant to a pure\n",
      "data science trajectory.\n",
      "#####################This is the GPT output.#########################\n"
     ]
    }
   ],
   "source": [
    "get_summer_school_introduction(\"I want to study data science.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for bse_data_science saved successfully! The similarity is 0.42781849733244315\n",
      "Similarity for bse_labor saved successfully! The similarity is 0.24077832250917902\n",
      "Similarity for cemfi_metrics saved successfully! The similarity is 0.28418814722981484\n",
      "Similarity for cage_research_training saved successfully! The similarity is 0.38982762345272753\n",
      "The most similar summer school to the question is bse_data_science\n",
      "#####################This is the GPT output.#########################\n",
      "To study data science in the UK, the most relevant option from the provided summer schools is the\n",
      "**CAGE Research Training** program at the University of Warwick.  **Reasoning:**  1. **Location**:\n",
      "The CAGE Research Training is specifically held in the UK (University of Warwick), while the other\n",
      "program, BSE Data Science Summer School, is held in Barcelona, Spain. 2. **Content**: The topics\n",
      "covered in the CAGE Research Training program include a variety of important data skills such as\n",
      "coding with Python, data management, digitisation of data, and big data analysis on cloud platforms\n",
      "(AWS). These are highly relevant and comprehensive in the field of data science. 3. **Targeted\n",
      "Learning**: The program's structure, which includes both lectures and hands-on participatory work,\n",
      "ensures a deep understanding and practical application of the concepts, which is crucial for data\n",
      "science studies.  Thus, due to its UK location and relevant content, CAGE Research Training is the\n",
      "appropriate choice for studying data science in the UK.\n",
      "#####################This is the GPT output.#########################\n"
     ]
    }
   ],
   "source": [
    "get_summer_school_introduction(\"I want to study data science in the UK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for bse_data_science saved successfully! The similarity is 0.46003353088051335\n",
      "Similarity for bse_labor saved successfully! The similarity is 0.2906568685401911\n",
      "Similarity for cemfi_metrics saved successfully! The similarity is 0.3167427620699821\n",
      "Similarity for cage_research_training saved successfully! The similarity is 0.45464936212676893\n",
      "The most similar summer school to the question is bse_data_science\n",
      "#####################This is the GPT output.#########################\n",
      "The question asks specifically about studying data science in the UK and the relevant professors.\n",
      "Based on the context provided, the most relevant summer school for data science in the UK is the one\n",
      "held at the University of Warwick (cage_research_training). Here are the associated professors and\n",
      "lecturers for this summer school:  - Professor Mirko Draca, University of Warwick (CAGE Director) -\n",
      "Arthur Turrell (Bank of England) - Eric Melander (University of Birmingham) - Peter John Lambert\n",
      "(London School of Economics - LSE) - Marie Segger (The Economist magazine)  Therefore, if you want\n",
      "to study data science in the UK, these are the main professors and presenters who will be involved\n",
      "in your education at the CAGE Research Training summer school.\n",
      "#####################This is the GPT output.#########################\n"
     ]
    }
   ],
   "source": [
    "get_summer_school_introduction(\"I want to study data science in the UK. Who will be my professors?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for bse_data_science saved successfully! The similarity is 0.36381672150420563\n",
      "Similarity for bse_labor saved successfully! The similarity is 0.41320797854614466\n",
      "Similarity for cemfi_metrics saved successfully! The similarity is 0.26258697490214833\n",
      "Similarity for cage_research_training saved successfully! The similarity is 0.33635363581293765\n",
      "The most similar summer school to the question is bse_labor\n",
      "#####################This is the GPT output.#########################\n",
      "If you want to study on the beach, the best options among the summer schools listed are the ones\n",
      "held at the Barcelona School of Economics (BSE). Both the **bse_data_science** and **bse_labor**\n",
      "summer schools are conducted in Barcelona, a city renowned for its beautiful beaches and vibrant\n",
      "coastal atmosphere.   Here's a brief breakdown:  1. **bse_data_science**:    - Focus: Machine\n",
      "learning, data science methodologies, and applying these techniques using tools like Python and R.\n",
      "- Ideal for: Those interested in hands-on learning and practical applications of machine learning\n",
      "and data science.  2. **bse_labor**:    - Focus: Labor economics, covering both macro and micro\n",
      "labor contexts, theory, empirical evidence, and economic policy.    - Ideal for: Graduate students,\n",
      "academics, and practitioners interested in expanding their knowledge in labor economics.  Both\n",
      "programs not only provide in-depth and specialized education but also offer the opportunity to enjoy\n",
      "Barcelona's stunning beaches and vibrant city life during the summer months. This combination of\n",
      "rigorous academic engagement and a relaxing beach environment makes the BSE summer schools the best\n",
      "choice for your preference.\n",
      "#####################This is the GPT output.#########################\n"
     ]
    }
   ],
   "source": [
    "get_summer_school_introduction(\"I want to study on the beach. What are the best summer schools for me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
